{
 "metadata": {
  "name": "",
  "signature": "sha256:fa7c9d32f392f5cfcc22fc51d07ed3145ea5dcc450f152a592d40bbc64fe2571"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "import sys\n",
      "import glob\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "%matplotlib inline\n",
      "%precision 4\n",
      "plt.style.use('ggplot')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import scipy.linalg as la\n",
      "import scipy.stats as st"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import cPickle"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "np.set_printoptions(formatter={'float': '{: 0.3f}'.format})"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Latent Semantic Analysis (LSA) is a method for reducing the dimnesionality of documents treated as a bag of words. It is used for document classification, clustering and retrieval. For example, LSA can be used to search for prior art given a new patent application. In this homework, we will implement a small library for simple latent semantic analysis as a practical example of the application of SVD. The ideas are very similar to PCA.\n",
      "\n",
      "We will implement a toy example of LSA to get familair with the ideas. If you want to use LSA or similar methods for statiscal language analyiss, the most efficient Python library is probably [gensim](https://radimrehurek.com/gensim/) - this also proivdes an online alggorith - i.e. the training information can be continuously updated. Other useful functions for processing natural language can be found in the [Natural Lnaguage Toolkit](http://www.nltk.org/)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Note**: The SVD from scipy.linalg performs a full decomposition, which is inefficient since we only need to decompose until we get the first k singluar values. If the SVD from `scipy.linalg` is too slow, please use the `sparsesvd` function from the [sparsesvd](https://pypi.python.org/pypi/sparsesvd/) package to perform SVD instead.  You can install in the usual way with \n",
      "```\n",
      "!pip install sparsesvd\n",
      "```\n",
      "\n",
      "Then import the following\n",
      "```python\n",
      "from sparsesvd import sparsesvd \n",
      "from scipy.sparse import csc_matrix \n",
      "```\n",
      "\n",
      "and use as follows\n",
      "```python\n",
      "sparsesvd(csc_matrix(M), k=10)\n",
      "```"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 1 (10 points)**.  Calculating pairwise distance matrices.\n",
      "\n",
      "Suppose we want to construct a distance matrix between the rows of a matrix. For example, given the matrix \n",
      "\n",
      "```python\n",
      "M = np.array([[1,2,3],[4,5,6]])\n",
      "```\n",
      "\n",
      "the distance matrix using Eucliden distance as the measure would be\n",
      "```python\n",
      "[[ 0.000  1.414  2.828]\n",
      " [ 1.414  0.000  1.414]\n",
      " [ 2.828  1.414  0.000]] \n",
      "```\n",
      "if $M$ was a collection of column vectors.\n",
      "\n",
      "Write a function to calculate the pairwise-distance matrix given the matrix $M$ and some abritrary distance function. Your functions should have the following signature:\n",
      "```\n",
      "def func_name(M, distance_func):\n",
      "    pass\n",
      "```\n",
      "\n",
      "0. Write a distance function for the Euclidean, squared Euclidean and cosine measures.\n",
      "1. Write the function using looping for M as a collection of row vecotrs.\n",
      "2. Write the function using looping for M as a collection of column vectors.\n",
      "3. Wrtie the function using broadcasting for M as a colleciton of row vectors.\n",
      "4. Write the function using broadcasting for M as a colleciton of column vectors. \n",
      "\n",
      "For 3 and 4, try to avoid using transposition. Check that all four functions give the same result when applied to the given matrix $M$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import math\n",
      "\n",
      "# Your code here\n",
      "#def Euclid_dist(A,B):\n",
      "#    return np.linalg.norm(A-B)\n",
      "\n",
      "#def Euclid2_dist(A,B):\n",
      "#    return np.linalg.norm(A-B)**2\n",
      "\n",
      "def cosine_dist(A,B):\n",
      "    return np.dot(A,B)/(np.linalg.norm(A)*np.linalg.norm(B))\n",
      "\n",
      "def Euclid_dist(A,B):\n",
      "    return np.sqrt(sum((A-B)**2))\n",
      "\n",
      "def Euclid2_dist(A,B):\n",
      "    return sum((A-B)**2)\n",
      "\n",
      "#def cosine_dist(A,B):\n",
      "#    return np.dot(A,B)/(math.sqrt(Euclid2_dist(A,np.zeros(len(A)))*Euclid2_dist(B,np.zeros(len(B)))))\n",
      "\n",
      "M = np.array([[1,2,3],[4,5,6]])\n",
      "\n",
      "#### Using looping ####\n",
      "def row_dist1(M, distance_func):\n",
      "    num_row = M.shape[0]\n",
      "    answer = np.zeros((num_row, num_row))\n",
      "    \n",
      "    for i in range(0,num_row):\n",
      "        for j in range(0,num_row):\n",
      "            answer[i,j] = distance_func(M[i,:],M[j,:])\n",
      "    return answer\n",
      "        \n",
      "def col_dist1(M, distance_func):\n",
      "    num_col = M.shape[1]\n",
      "    answer = np.zeros((num_col, num_col))\n",
      "    \n",
      "    for i in range(0,num_col):\n",
      "        for j in range(0,num_col):\n",
      "            answer[i,j] = distance_func(M[:,i],M[:,j])\n",
      "    return answer\n",
      "\n",
      "\n",
      "#### Using broadcasting ####\n",
      "#def row_dist2(M, distance_func):\n",
      "#    answer = distance_func((M-M[:,np.newaxis]).T, (np.zeros((M.shape[0],2,M.shape[1]))).T)\n",
      "#    return answer\n",
      "\n",
      "def row_dist2(M, distance_func):\n",
      "    answer = distance_func((M-M[:,np.newaxis]).T, (np.zeros((M.shape[0],2,M.shape[1]))).T)\n",
      "    return answer\n",
      "\n",
      "\n",
      "def col_dist2(M, distance_func):\n",
      "    answer = distance_func((M.T-M.T[:,np.newaxis]).T, (np.zeros((M.T.shape[0],1,M.T.shape[1]))).T)\n",
      "    return answer\n",
      "\n",
      "print \"Using Euclidean distance:\"\n",
      "print \"Row distance using looping\"\n",
      "print row_dist1(M,Euclid_dist)\n",
      "print \"Row distance using broadcasting\"\n",
      "print row_dist2(M,Euclid_dist), '\\n'\n",
      "\n",
      "print \"Column distance using looping\"\n",
      "print col_dist1(M,Euclid_dist)\n",
      "print \"Column distance using broadcasting\"\n",
      "print col_dist2(M,Euclid_dist), '\\n'\n",
      "\n",
      "print \"Using Euclidean^2 distance:\"\n",
      "print \"Row distance using looping\"\n",
      "print row_dist1(M,Euclid2_dist)\n",
      "print \"Row distance using broadcasting\"\n",
      "print row_dist2(M,Euclid2_dist), '\\n'\n",
      "\n",
      "print \"Column distance using looping\"\n",
      "print col_dist1(M,Euclid2_dist)\n",
      "print \"Column distance using broadcasting\"\n",
      "print col_dist2(M,Euclid2_dist), '\\n'\n",
      "\n",
      "print \"Using cosine distance:\"\n",
      "print \"Row distance using looping\"\n",
      "print row_dist1(M,cosine_dist)\n",
      "print \"Row distance using broadcasting is not working!!!\"\n",
      "#print row_dist2(M,cosine_dist), '\\n'\n",
      "\n",
      "print \"Column distance using looping\"\n",
      "print col_dist1(M,cosine_dist)\n",
      "print \"Column distance using broadcasting is not working!!!\"\n",
      "#print col_dist2(M,cosine_dist), '\\n'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Using Euclidean distance:\n",
        "Row distance using looping\n",
        "[[ 0.000  5.196]\n",
        " [ 5.196  0.000]]\n",
        "Row distance using broadcasting\n",
        "[[ 0.000  5.196]\n",
        " [ 5.196  0.000]] \n",
        "\n",
        "Column distance using looping\n",
        "[[ 0.000  1.414  2.828]\n",
        " [ 1.414  0.000  1.414]\n",
        " [ 2.828  1.414  0.000]]\n",
        "Column distance using broadcasting\n",
        "[[ 0.000  1.414  2.828]\n",
        " [ 1.414  0.000  1.414]\n",
        " [ 2.828  1.414  0.000]] \n",
        "\n",
        "Using Euclidean^2 distance:\n",
        "Row distance using looping\n",
        "[[ 0.000  27.000]\n",
        " [ 27.000  0.000]]\n",
        "Row distance using broadcasting\n",
        "[[ 0.000  27.000]\n",
        " [ 27.000  0.000]] \n",
        "\n",
        "Column distance using looping\n",
        "[[ 0.000  2.000  8.000]\n",
        " [ 2.000  0.000  2.000]\n",
        " [ 8.000  2.000  0.000]]\n",
        "Column distance using broadcasting\n",
        "[[ 0.000  2.000  8.000]\n",
        " [ 2.000  0.000  2.000]\n",
        " [ 8.000  2.000  0.000]] \n",
        "\n",
        "Using cosine distance:\n",
        "Row distance using looping\n",
        "[[ 1.000  0.975]\n",
        " [ 0.975  1.000]]\n",
        "Row distance using broadcasting is not working!!!\n",
        "Column distance using looping\n",
        "[[ 1.000  0.991  0.976]\n",
        " [ 0.991  1.000  0.997]\n",
        " [ 0.976  0.997  1.000]]\n",
        "Column distance using broadcasting is not working!!!\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 2 (10 points)**. Write 3 functions to calculate the term frequency (tf), the inverse document frequency (idf) and the product (tf-idf). Each function should take a single argument `docs`, which is a dictionary of (key=identifier, value=dcoument text) pairs, and return an appropriately sized array. Convert '-' to ' ' (space), remove punctuation, convert text to lowercase and split on whitespace to generate a collection of terms from the dcoument text.\n",
      "\n",
      "- tf = the number of occurrences of term $i$ in document $j$\n",
      "- idf = $\\log \\frac{n}{1 + \\text{df}_i}$ where $n$ is the total number of documents and $\\text{df}_i$ is the number of documents in which term $i$ occurs.\n",
      "\n",
      "Print the table of tf-idf values for the following document collection\n",
      "\n",
      "```\n",
      "s1 = \"The quick brown fox\"\n",
      "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
      "s3 = \"The the the lazy dog elephant.\"\n",
      "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
      "\n",
      "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "def tfs(docs=None):\n",
      "    n = len(docs)\n",
      "    keys = list(docs.keys())\n",
      "    docWords = []\n",
      "        \n",
      "    for key in keys:\n",
      "        docs[key] = re.sub('[{}]'.format(re.escape(string.punctuation)),'',docs[key]).replace('-',' ').lower()\n",
      "        words    = docWords.append(set(docs[key].split()))\n",
      "\n",
      "    uniqueWords = list(set(item for sublist in docWords for item in sublist))\n",
      "    num_unique  = len(uniqueWords)\n",
      "        \n",
      "    term_freq_matrix = np.zeros((num_unique,n))\n",
      "    for i in np.arange(num_unique):\n",
      "        for j in np.arange(n):\n",
      "            term_freq_matrix[i,j] = docs[keys[j]].split().count(uniqueWords[i])\n",
      "\n",
      "    return pd.DataFrame(term_freq_matrix,index=uniqueWords, columns=keys).sort(axis=1).sort(axis=0)\n",
      "'''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import string\n",
      "import re\n",
      "import math\n",
      "\n",
      "# Your code here\n",
      "s1 = \"The quick brown fox\"\n",
      "s2 = \"Brown fox jumps over the jumps jumps jumps\"\n",
      "s3 = \"The the the lazy dog elephant.\"\n",
      "s4 = \"The the the the the dog peacock lion tiger elephant\"\n",
      "\n",
      "docs = {'s1': s1, 's2': s2, 's3': s3, 's4': s4}\n",
      "\n",
      "def tf(doc):\n",
      "    \"\"\"Returns the number of times each term occurs in a dcoument.\n",
      "    We preprocess the document to strip punctuation and convert to lowercase.\n",
      "    Terms are found by splitting on whitespace.\"\"\"\n",
      "    process     = re.sub('[{}]'.format(re.escape(string.punctuation)),'',doc).replace('-',' ').lower()\n",
      "    uniqueWords = set(process.split())\n",
      "    counts      = list(process.count(word) for word in uniqueWords)\n",
      "    \n",
      "    return pd.DataFrame(counts,index=uniqueWords).sort(axis=0)\n",
      "\n",
      "def tfs(docs=None):\n",
      "    \"\"\"Create a term frequency dataframe from a dictionary of documents.\"\"\"\n",
      "    alldocs = list(tf(docs[key]) for key in docs.keys())\n",
      "    \n",
      "    result = pd.concat(alldocs,axis=1).fillna(0)\n",
      "    result.columns = docs.keys()\n",
      "    \n",
      "    return result.sort(axis=1)\n",
      "\n",
      "def idf(docs=None):\n",
      "    \"\"\"Find inverse document frequency series from a dictionary of documents.\"\"\"\n",
      "    ndocs = len(docs)\n",
      "    \n",
      "    words = tfs(docs)\n",
      "    words[words>1]=1\n",
      "    return np.log(ndocs / (1+words.sum(axis=1)))\n",
      "\n",
      "def tf_idf(docs=None):\n",
      "    \"\"\"Return the product of the term-frequency and inverse document frequency.\"\"\"\n",
      "    wordFreq = tfs(docs)\n",
      "    docFreq  = idf(docs)\n",
      "    return wordFreq.mul(docFreq,axis='index')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print \"Term frequncies by document:\", '\\n', tfs(docs), '\\n'\n",
      "print \"Inverse document frequencies:\", '\\n', idf(docs), '\\n'\n",
      "print \"Their product is: \", '\\n', tf_idf(docs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Term frequncies by document: \n",
        "          s1  s2  s3  s4\n",
        "brown      1   1   0   0\n",
        "dog        0   0   1   1\n",
        "elephant   0   0   1   1\n",
        "fox        1   1   0   0\n",
        "jumps      0   4   0   0\n",
        "lazy       0   0   1   0\n",
        "lion       0   0   0   1\n",
        "over       0   1   0   0\n",
        "peacock    0   0   0   1\n",
        "quick      1   0   0   0\n",
        "the        1   1   3   5\n",
        "tiger      0   0   0   1 \n",
        "\n",
        "Inverse document frequencies: \n",
        "brown       0.287682\n",
        "dog         0.287682\n",
        "elephant    0.287682\n",
        "fox         0.287682\n",
        "jumps       0.693147\n",
        "lazy        0.693147\n",
        "lion        0.693147\n",
        "over        0.693147\n",
        "peacock     0.693147\n",
        "quick       0.693147\n",
        "the        -0.223144\n",
        "tiger       0.693147\n",
        "dtype: float64 \n",
        "\n",
        "Their product is:  \n",
        "                s1        s2        s3        s4\n",
        "brown     0.287682  0.287682  0.000000  0.000000\n",
        "dog       0.000000  0.000000  0.287682  0.287682\n",
        "elephant  0.000000  0.000000  0.287682  0.287682\n",
        "fox       0.287682  0.287682  0.000000  0.000000\n",
        "jumps     0.000000  2.772589  0.000000  0.000000\n",
        "lazy      0.000000  0.000000  0.693147  0.000000\n",
        "lion      0.000000  0.000000  0.000000  0.693147\n",
        "over      0.000000  0.693147  0.000000  0.000000\n",
        "peacock   0.000000  0.000000  0.000000  0.693147\n",
        "quick     0.693147  0.000000  0.000000  0.000000\n",
        "the      -0.223144 -0.223144 -0.669431 -1.115718\n",
        "tiger     0.000000  0.000000  0.000000  0.693147\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 3 (10 points)**. \n",
      "\n",
      "1. Write a function that takes a matrix $M$ and an integer $k$ as arguments, and reconstructs a reduced matrix using only the $k$ largest singular values. Use the `scipy.linagl.svd` function to perform the decomposition. Thi is the least squares approximation to the matrix $M$ in $k$ dimensions.\n",
      "\n",
      "2. Apply the function you just wrote to the following term-frequency matrix for a set of $9$ documents using $k=2$ and print the reconstructed matrix $M'$.\n",
      "```\n",
      "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "       [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "       [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "       [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "       [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "       [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "       [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "       [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
      "```\n",
      "\n",
      "3. Calculate the pairwise correlation matrix for the original matrix M and the reconstructed matrix using $k=2$ singular values (you may use [scipy.stats.spearmanr](http://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.spearmanr.html) to do the calculations). Consider the fist 5 sets of documents as one group $G1$ and the last 4 as another group $G2$ (i.e. first 5 and last 4 columns). What is the average within group correlation for $G1$, $G2$ and the average cross-group correlation for G1-G2 using either $M$ or $M'$. (Do not include self-correlation in the within-group calculations.)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "def svdReduce(M, k):\n",
      "    # First perform svd decomposition\n",
      "    # Take only first k singular values and their singular vectors,\n",
      "    #  and take their product (assuming singular values in a matrix)\n",
      "    U,s,Vh = la.svd(M,full_matrices=False)\n",
      "    S = la.diagsvd(s,len(s),len(s))\n",
      "    return np.dot(U[:,0:k], np.dot(S[0:k,0:k],Vh[0:k,:]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "M = np.array([[1, 0, 0, 1, 0, 0, 0, 0, 0],\n",
      "    [1, 0, 1, 0, 0, 0, 0, 0, 0],\n",
      "    [1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 1, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 1, 1, 2, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
      "    [0, 0, 1, 1, 0, 0, 0, 0, 0],\n",
      "    [0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
      "    [0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 1, 1, 1],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 1, 1]])\n",
      "\n",
      "Mprime = svdReduce(M,2)\n",
      "print Mprime"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[[ 0.162  0.400  0.379  0.468  0.176 -0.053 -0.115 -0.159 -0.092]\n",
        " [ 0.141  0.370  0.329  0.400  0.165 -0.033 -0.071 -0.097 -0.043]\n",
        " [ 0.152  0.505  0.358  0.410  0.236  0.024  0.060  0.087  0.124]\n",
        " [ 0.258  0.841  0.606  0.697  0.392  0.033  0.083  0.122  0.187]\n",
        " [ 0.449  1.234  1.051  1.266  0.556 -0.074 -0.155 -0.210 -0.049]\n",
        " [ 0.160  0.582  0.375  0.417  0.277  0.056  0.132  0.189  0.217]\n",
        " [ 0.160  0.582  0.375  0.417  0.277  0.056  0.132  0.189  0.217]\n",
        " [ 0.218  0.550  0.511  0.628  0.243 -0.065 -0.143 -0.197 -0.108]\n",
        " [ 0.097  0.532  0.230  0.212  0.267  0.137  0.315  0.444  0.425]\n",
        " [-0.061  0.232 -0.139 -0.266  0.145  0.240  0.546  0.767  0.664]\n",
        " [-0.065  0.335 -0.146 -0.301  0.203  0.306  0.695  0.977  0.849]\n",
        " [-0.043  0.254 -0.097 -0.208  0.152  0.221  0.503  0.707  0.616]]\n"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Average within correlation for G1 using M\n",
      "total = 0\n",
      "count = 0\n",
      "for i in range(0,5):\n",
      "    for j in range(0,5):\n",
      "        if(i != j):\n",
      "            total += st.spearmanr(M[:,i],M[:,j],axis=0)[0]\n",
      "            count += 1\n",
      "print \"The within correlation for G1 using M is:\", total / count\n",
      "\n",
      "# Average within correlation for G2 using M\n",
      "total = 0\n",
      "count = 0\n",
      "for i in range(5,9):\n",
      "    for j in range(5,9):\n",
      "        if(i != j):\n",
      "            total += st.spearmanr(M[:,i],M[:,j],axis=0)[0]\n",
      "            count += 1\n",
      "print \"The within correlation for G2 using M is:\", total / count\n",
      "\n",
      "# Average between correlation for G1, G2 using M\n",
      "total = 0\n",
      "count = 0\n",
      "for i in range(0,5):\n",
      "    for j in range(5,9):\n",
      "        total += st.spearmanr(M[:,i],M[:,j],axis=0)[0]\n",
      "        count += 1\n",
      "print \"The average between correlation for G1 and G2 using M is:\", total / count, '\\n'\n",
      "\n",
      "\n",
      "\n",
      "# Average within correlation for G1 using M'\n",
      "total = 0\n",
      "count = 0\n",
      "for i in range(0,5):\n",
      "    for j in range(0,5):\n",
      "        if(i != j):\n",
      "            total += st.spearmanr(Mprime[:,i],Mprime[:,j],axis=0)[0]\n",
      "            count += 1\n",
      "print \"The within correlation for G1 using M' is:\", total / count\n",
      "\n",
      "# Average within correlation for G2 using M'\n",
      "total = 0\n",
      "count = 0\n",
      "for i in range(5,9):\n",
      "    for j in range(5,9):\n",
      "        if(i != j):\n",
      "            total += st.spearmanr(Mprime[:,i],Mprime[:,j],axis=0)[0]\n",
      "            count += 1\n",
      "print \"The within correlation for G2 using M' is:\", total / count\n",
      "\n",
      "# Average between correlation for G1, G2 using M'\n",
      "total = 0\n",
      "count = 0\n",
      "for i in range(0,5):\n",
      "    for j in range(5,9):\n",
      "        total += st.spearmanr(Mprime[:,i],Mprime[:,j],axis=0)[0]\n",
      "        count += 1\n",
      "print \"The average between correlation for G1 and G2 using M' is:\", total / count\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The within correlation for G1 using M is: 0.0105776866299\n",
        "The within correlation for G2 using M is: 0.43511771482\n",
        "The average between correlation for G1 and G2 using M is: -0.307562188906 \n",
        "\n",
        "The within correlation for G1 using M' is: 0.866042884512\n",
        "The within correlation for G2 using M' is: 0.98951048951\n",
        "The average between correlation for G1 and G2 using M' is: -0.678168764439\n"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "**Exercise 4 (20 points)**. Clustering with LSA\n",
      "\n",
      "1. Begin by loading a pubmed database of selected article titles using 'cPickle'. With the following:\n",
      "```import cPickle\n",
      "docs = cPickle.load(open('pubmed.pic'))```\n",
      "\n",
      "    Create a tf-idf matrix for every term that appears at least once in any of the documents. What is the shape of the tf-idf matrix? \n",
      "\n",
      "2. Perform SVD on the tf-idf matrix to obtain $U \\Sigma V^T$ (often written as $T \\Sigma D^T$ in this context with $T$ representing the terms and $D$ representing the documents). If we set all but the top $k$ singular values to 0, the reconstructed matrix is essentially $U_k \\Sigma_k V_k^T$, where $U_k$ is $m \\times k$, $\\Sigma_k$ is $k \\times k$ and $V_k^T$ is $k \\times n$. Terms in this reduced space are represented by $U_k \\Sigma_k$ and documents by $\\Sigma_k V^T_k$. Reconstruct the matrix using the first $k=10$ singular values.\n",
      "\n",
      "3. Use agglomerative hierachical clustering with complete linkage to plot a dendrogram and comment on the likely number of  document clusters with $k = 100$. Use the dendrogram function from [SciPy ](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.cluster.hierarchy.dendrogram.html).\n",
      "\n",
      "4. Determine how similar each of the original documents is to the new document `mystery.txt`. Since $A = U \\Sigma V^T$, we also have $V = A^T U S^{-1}$ using orthogonality and the rule for transposing matrix products. This suggests that in order to map the new document to the same concept space, first find the tf-idf vector $v$ for the new document - this must contain all (and only) the terms present in the existing tf-idx matrix. Then the query vector $q$ is given by $v^T U_k \\Sigma_k^{-1}$. Find the 10 documents most similar to the new document and the 10 most dissimilar. \n",
      "\n",
      "5. Many documents often have some bolierplate materrial such as Organization informaiton, Copyright etc at the front or back of the dcoument. Does it matter that the front and back matter of each document is essentially identical for either LSA-based clustering (part 3) or information retrieval (part 4)? Why or why not?"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Your code here\n",
      "docs = cPickle.load(open('pubmed.pic'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "part_a = tf_idf(docs)\n",
      "print part_a.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "(6906, 178)\n"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The shape of the tf-idf matrix is 6906 rows (words) and 178 columns (documents)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "k = 100\n",
      "docs_k = svdReduce(part_a,k)\n",
      "\n",
      "U,s,Vh = la.svd(part_a,full_matrices=False)\n",
      "U_k  = U[:,0:k]\n",
      "s_k  = la.diagsvd(s[0:k],k,k)\n",
      "Vh_k = Vh[0:k,:]\n",
      "\n",
      "doc_reduced = np.dot(s_k,Vh_k)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from scipy.cluster.hierarchy import linkage, dendrogram\n",
      "import scipy.cluster.hierarchy as scch\n",
      "\n",
      "distance = col_dist1(doc_reduced, cosine_dist)\n",
      "R = scch.dendrogram(scch.linkage(distance, method='complete'),orientation=\"right\")\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEDCAYAAAAhsS8XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAoFAMMgQgV0gEAgGGSKwCwQCwSDj/wPwCRq+SbX6ogAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure at 0x7f299e996790>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It appears that the likely number of clusters using $k=100$ is 5 clusters."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mystery_text  = open('mystery.txt','r').read().replace('\\r\\n', ' ')\n",
      "mystery       = {'mystery': mystery_text}\n",
      "\n",
      "### Keep only words that are previously found in the corpus\n",
      "# Create tf_idf matrix\n",
      "mystery_tf = tf_idf(mystery)\n",
      "\n",
      "# Keep only words from mystery.txt that were previously found\n",
      "mystery_tf = mystery_tf[(mystery_tf.index).isin(part_a.index)]\n",
      "\n",
      "# Extend the mystery_tf vector to include all words previously found \n",
      "# with zero tf_idf score for words in the corpus not in mystery.txt\n",
      "mystery_tf = mystery_tf.append(pd.DataFrame(data  = np.zeros(len(part_a.index - mystery_tf.index)),\n",
      "                                            index = part_a.index - mystery_tf.index,\n",
      "                                            columns=['mystery']))\n",
      "\n",
      "# Map mystery text to concept space\n",
      "q = np.dot(mystery_tf.T, np.dot(U_k,la.inv(s_k)))\n",
      "\n",
      "# Calculate distance between mystery.txt and the other documents\n",
      "mystery_dist = [cosine_dist(q, doc_reduced[:,i])[0] for i in range(0,part_a.shape[1])]\n",
      "\n",
      "# Most similar documents\n",
      "similar_keys   = np.argpartition(np.array(mystery_dist),10)[:10]\n",
      "similar_titles = [docs.keys()[K] for K in similar_keys]\n",
      "\n",
      "print '**** Documents most similar to the mystery text ****'\n",
      "for title in similar_titles:\n",
      "    print title, '\\n'\n",
      "\n",
      "# Most different documents\n",
      "different_keys   = np.argpartition(np.array(mystery_dist),-10)[-10:]\n",
      "different_titles = [docs.keys()[K] for K in different_keys]\n",
      "\n",
      "print '\\n', '**** Documents most different to the mystery text ****'\n",
      "for title in different_titles:\n",
      "    print title, '\\n'\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "**** Documents most similar to the mystery text ****\n",
        "[Antiproliferative effect of silencing mTOR gene on MCL Jeko-1 cell line and its mechanism]. \n",
        "\n",
        "Vitamin D decreases the secretion of eotaxin and RANTES in nasal polyp fibroblasts derived from Taiwanese patients with chronic rhinosinusitis with nasal polyps. \n",
        "\n",
        "Vitamin D deficiency in pregnant women impairs Regulatory T cell function. \n",
        "\n",
        "Lunasin Alleviates Allergic Airway Inflammation while Increases Antigen-Specific Tregs. \n",
        "\n",
        "Compartmentalization of GABA Synthesis by GAD67 Differs between Pancreatic Beta Cells and Neurons. \n",
        "\n",
        "IL-18 is associated with protection against rhinovirus-induced colds and asthma exacerbations. \n",
        "\n",
        "On the Functional Overlap between Complement and Anti-Microbial Peptides. \n",
        "\n",
        "Molecular basis of carcinogenesis in diabetic patients (Review). \n",
        "\n",
        "Evaluation of Ebola virus Inactivation Procedures for Plasmodium falciparum Malaria Diagnostics. \n",
        "\n",
        "A CD45-based barcoding approach to multiplex mass-cytometry (CyTOF). \n",
        "\n",
        "\n",
        "**** Documents most different to the mystery text ****\n",
        "Ni(II)NTA AuNPs as a low-resource malarial diagnostic platform for the rapid colorimetric detection of Plasmodium falciparum Histidine-Rich Protein-2. \n",
        "\n",
        "Interactions of antitumour Sialyl Lewis X-liposomes with vascular endothelial cells. \n",
        "\n",
        "Automatic Differentiation of Normal and Continuous Adventitious Respiratory Sounds Using Ensemble Empirical Mode Decomposition and Instantaneous Frequency. \n",
        "\n",
        "Role of red blood cell distribution in predicting drug-eluting stent restenosis in patients with stable angina pectoris after coronary stenting. \n",
        "\n",
        "Increased sample volume and use of quantitative reverse-transcription PCR can improve prediction of liver-to-blood inoculum size in controlled human malaria infection studies. \n",
        "\n",
        "In situ hybridization and sequence analysis reveal an association of Plasmodium spp. with mortalities in wild passerine birds in Austria. \n",
        "\n",
        "Lower anti-echovirus antibody responses in children presenting to hospital with asthma exacerbations. \n",
        "\n",
        "Lineage-related cytotoxicity and clonogenic profile of 1,4-benzoquinone-exposed hematopoietic stem and progenitor cells. \n",
        "\n",
        "Childhood Asthma Hospital Discharge Medication Fills and Risk of Subsequent Readmission. \n",
        "\n",
        "In Vitro Induction of Human Adipose-Derived Stem Cells into Lymphatic Endothelial-Like Cells. \n",
        "\n"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It should not matter if the same exact boilerplate language occurs at the beginning of every document, since these words can not distinguish documents or concepts from each other if they exist in every document."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Notes on the Pubmed articles\n",
      "----\n",
      "\n",
      "These were downloaded wiht the follwoing script.\n",
      "\n",
      "```python\n",
      "from Bio import Entrez, Medline\n",
      "Entrez.email = \"YOUR EMAIL HERE\"\n",
      "import cPickle\n",
      "\n",
      "try:\n",
      "    docs = cPickle.load(open('pubmed.pic'))\n",
      "except Exception, e:\n",
      "    print e\n",
      "\n",
      "    docs = {}\n",
      "    for term in ['plasmodium', 'diabetes', 'asthma', 'cytometry']:\n",
      "        handle = Entrez.esearch(db=\"pubmed\", term=term, retmax=50)\n",
      "        result = Entrez.read(handle)\n",
      "        handle.close()\n",
      "        idlist = result[\"IdList\"]\n",
      "        handle2 = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\")\n",
      "        result2 = Medline.parse(handle2)\n",
      "        for record in result2:\n",
      "            title = record.get(\"TI\", None)\n",
      "            abstract = record.get(\"AB\", None)\n",
      "            if title is None or abstract is None:\n",
      "                continue\n",
      "            docs[title] = '\\n'.join([title, abstract])\n",
      "            print title\n",
      "        handle2.close()\n",
      "    cPickle.dump(docs, open('pubmed.pic', 'w'))\n",
      "docs.values()\n",
      "```"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}